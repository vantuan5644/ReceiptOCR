{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plac\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./label_text_product_attrs.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'sale_price': 'ppu', 'final_price': 'total_price'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_name                                        img_1_padded_0.jpg\n",
       "text               04902430779746 NX DOWNY doahoa ngotngao\\nVAT10...\n",
       "sku                                                      4.90243E+12\n",
       "product_name                               NX DOWNY doahoa ngotngao \n",
       "quantity                                                           1\n",
       "ppu                                                        88,000.00\n",
       "total_price                                                88,000.00\n",
       "discounted_part                                                  NaN\n",
       "original_price                                            103,000.00\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = data.iloc[0]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04902430779746 NX DOWNY doahoa ngotngao\\nVAT10%   1    88,000.00    88,000.00 \\nGia goc:   103,000.00 \n"
     ]
    }
   ],
   "source": [
    "print(row['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = data.columns.difference(['image_name', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['discounted_part', 'original_price', 'ppu', 'product_name', 'quantity',\n",
       "       'sku', 'total_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 8, 15]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'ABC12345ABC12AAABC'\n",
    "def find_2nd(string, substring):\n",
    "   return string.find(substring, string.find(substring) + 1)\n",
    "find_2nd(a, '1')\n",
    "\n",
    "sub = 'ABC'\n",
    "import re\n",
    "[i for i in range(len(a)) if a.startswith(sub, i)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AABC'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_entities(row, debug=False):\n",
    "    row_entities = []\n",
    "    cache = []\n",
    "    text = row['text']\n",
    "    for attr in ['sku', 'product_name', 'quantity', 'ppu', 'total_price', 'discounted_part', 'original_price']:\n",
    "        if debug: print(attr)\n",
    "        if not pd.isnull(row[attr]):\n",
    "            value = str(row[attr])\n",
    "            \n",
    "            value = value.strip()\n",
    "            \n",
    "            if not value in text:\n",
    "                print(attr, value, 'not in text')\n",
    "                            \n",
    "            else:\n",
    "                try:\n",
    "                    indices = [i for i in range(len(text)) if text.startswith(value, i)]\n",
    "                    if debug: print(f'org indices = {indices}')\n",
    "                    \n",
    "                    indices_ = indices.copy()\n",
    "                    for item in indices_:\n",
    "                        if any(item in cache_ for cache_ in cache):\n",
    "                            indices.remove(item)\n",
    "                    if debug: print(f'indices = {indices}')\n",
    "                    start_index = indices[0]                   \n",
    "                    \n",
    "                    end_index = start_index + len(value)\n",
    "                    cache.append(range(start_index, end_index))\n",
    "                    if debug: print(f'cache = {cache}')\n",
    "                    if start_index < 0:\n",
    "                        print(start_index)\n",
    "                    if end_index < 0:\n",
    "                        print(end_index)\n",
    "                    row_entities.append((start_index, end_index, attr))\n",
    "                except Exception as e:\n",
    "                    print(row)\n",
    "                    print(text)\n",
    "                    print('Error', row_entities, value)\n",
    "                    raise e\n",
    "                    \n",
    "    for i, item in enumerate(row_entities):\n",
    "        if item[-1] == 'product_name':\n",
    "            product_name_range = item[0:-1]\n",
    "            product_name_id = i\n",
    "\n",
    "    if debug: print('Product name ranges', product_name_range)\n",
    "\n",
    "    splits = row.text[product_name_range[0]: product_name_range[1]].split(' ')\n",
    "\n",
    "    ranges = []\n",
    "    for item in splits:\n",
    "        ranges.append((row.text.find(item), row.text.find(item) + len(item), 'product_name'))\n",
    "\n",
    "    row_entities.pop(product_name_id)\n",
    "    row_entities += ranges\n",
    "    \n",
    "    def is_overlapped(entities):\n",
    "        ranges = [range(item[0], item[1]) for item in entities]\n",
    "        if debug: print('Total ranges', ranges)\n",
    "        return len(reduce(lambda x, y: set(x).intersection(y), ranges)) > 0\n",
    "    \n",
    "    from functools import reduce\n",
    "    \n",
    "    assert not is_overlapped(row_entities)\n",
    "    return row_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = data.iloc[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sku\n",
      "sku 4.90243E+12 not in text\n",
      "product_name\n",
      "org indices = [15]\n",
      "indices = [15]\n",
      "cache = [range(15, 39)]\n",
      "quantity\n",
      "org indices = [9, 44, 50, 55, 69, 93]\n",
      "indices = [9, 44, 50, 55, 69, 93]\n",
      "cache = [range(15, 39), range(9, 10)]\n",
      "ppu\n",
      "org indices = [55, 69]\n",
      "indices = [55, 69]\n",
      "cache = [range(15, 39), range(9, 10), range(55, 65)]\n",
      "total_price\n",
      "org indices = [55, 69]\n",
      "indices = [69]\n",
      "cache = [range(15, 39), range(9, 10), range(55, 65), range(69, 79)]\n",
      "discounted_part\n",
      "original_price\n",
      "org indices = [93]\n",
      "indices = [93]\n",
      "cache = [range(15, 39), range(9, 10), range(55, 65), range(69, 79), range(93, 103)]\n",
      "Product name ranges (15, 39)\n",
      "Total ranges [range(9, 10), range(55, 65), range(69, 79), range(93, 103), range(15, 17), range(18, 23), range(24, 30), range(31, 39)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(9, 10, 'quantity'),\n",
       " (55, 65, 'ppu'),\n",
       " (69, 79, 'total_price'),\n",
       " (93, 103, 'original_price'),\n",
       " (15, 17, 'product_name'),\n",
       " (18, 23, 'product_name'),\n",
       " (24, 30, 'product_name'),\n",
       " (31, 39, 'product_name')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = get_row_entities(row, debug=True)\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_name                                       img_16_padded_1.jpg\n",
      "text               04902430418287 NX DOWNY doahoa ngotngao\\nVAT10...\n",
      "sku                                                      4.90243E+12\n",
      "product_name                               NX DOWNY doahoa ngotngao \n",
      "quantity                                                           1\n",
      "ppu                                                       129,000.00\n",
      "total_price                                               129,000.00\n",
      "discounted_part                                                  NaN\n",
      "original_price                                            159,000.00\n",
      "Name: 56, dtype: object\n",
      "\n",
      "quantity: 1\n",
      "ppu: 129,000.00\n",
      "total_price: 129,000.00\n",
      "original_price: 159,000.00\n",
      "product_name: NX\n",
      "product_name: DOWNY\n",
      "product_name: doahoa\n",
      "product_name: ngotngao\n"
     ]
    }
   ],
   "source": [
    "print(row)\n",
    "print()\n",
    "for i, j, name in entities:\n",
    "    print(f\"{name}: {row['text'][i:j]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sku 4.90243E+12 not in text\n",
      "sku 8.9385E+12 not in text\n",
      "sku 8.9351E+12 not in text\n",
      "sku 8.93471E+12 not in text\n",
      "sku 8.93851E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93605E+12 not in text\n",
      "sku 8.9361E+12 not in text\n",
      "sku 8.93473E+12 not in text\n",
      "sku 8.93601E+12 not in text\n",
      "sku 8.93487E+12 not in text\n",
      "sku 8.93601E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 2.00013E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.85113E+12 not in text\n",
      "sku 8.85205E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.69122E+12 not in text\n",
      "sku 8.9348E+12 not in text\n",
      "sku 8.93482E+12 not in text\n",
      "sku 8.93602E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93511E+12 not in text\n",
      "sku 8.93604E+12 not in text\n",
      "sku 8.93507E+12 not in text\n",
      "sku 8.93468E+12 not in text\n",
      "sku 8.93487E+12 not in text\n",
      "sku 8.93522E+12 not in text\n",
      "sku 8.93607E+12 not in text\n",
      "sku 8.93501E+12 not in text\n",
      "sku 8.93603E+12 not in text\n",
      "sku 8.9385E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.85113E+12 not in text\n",
      "sku 8.93506E+12 not in text\n",
      "sku 8.93466E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.9385E+12 not in text\n",
      "sku 9.41501E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93467E+12 not in text\n",
      "sku 8.93506E+12 not in text\n",
      "sku 8.93458E+12 not in text\n",
      "sku 8.93524E+12 not in text\n",
      "sku 8.93476E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93604E+12 not in text\n",
      "sku 8.93467E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93471E+12 not in text\n",
      "sku 8.9385E+12 not in text\n",
      "sku 8.93467E+12 not in text\n",
      "sku 8.9361E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.9385E+12 not in text\n",
      "sku 8.936E+12 not in text\n",
      "sku 8.93467E+12 not in text\n",
      "sku 8.9385E+12 not in text\n",
      "sku 8.9385E+12 not in text\n",
      "sku 8.9348E+12 not in text\n",
      "sku 8.93467E+12 not in text\n",
      "sku 8.93459E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 5.99952E+12 not in text\n",
      "sku 8.9385E+12 not in text\n",
      "sku 8.93601E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93607E+12 not in text\n",
      "sku 8.93482E+12 not in text\n",
      "sku 8.93607E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.80135E+12 not in text\n",
      "sku 8.93456E+12 not in text\n",
      "sku 8.93521E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.85205E+12 not in text\n",
      "sku 8.93468E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93487E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93851E+12 not in text\n",
      "sku 8.93467E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93487E+12 not in text\n",
      "sku 8.93505E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93505E+12 not in text\n",
      "sku 8.93506E+12 not in text\n",
      "sku 2.00013E+12 not in text\n",
      "sku 8.85182E+12 not in text\n",
      "sku 8.9362E+12 not in text\n",
      "sku 8.93473E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.9348E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93487E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93471E+12 not in text\n",
      "sku 8.93506E+12 not in text\n",
      "sku 8.93515E+12 not in text\n",
      "sku 8.85009E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93601E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.9348E+12 not in text\n",
      "sku 8.80257E+12 not in text\n",
      "sku 8.93476E+12 not in text\n",
      "sku 8.93613E+12 not in text\n",
      "sku 8.93487E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93603E+12 not in text\n",
      "sku 8.9385E+12 not in text\n",
      "sku 8.88834E+12 not in text\n",
      "sku 8.93457E+12 not in text\n",
      "sku 8.85001E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93604E+12 not in text\n",
      "sku 8.93459E+12 not in text\n",
      "sku 8.93489E+12 not in text\n",
      "sku 8.85205E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93467E+12 not in text\n",
      "sku 8.93604E+12 not in text\n",
      "sku 8.93605E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93603E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.85958E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.69128E+12 not in text\n",
      "sku 8.93467E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.9348E+12 not in text\n",
      "sku 8.93457E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93524E+12 not in text\n",
      "sku 8.93513E+12 not in text\n",
      "sku 8.93471E+12 not in text\n",
      "sku 8.93467E+12 not in text\n",
      "sku 8.93604E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93605E+12 not in text\n",
      "sku 8.93487E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93605E+12 not in text\n",
      "sku 8.93602E+12 not in text\n",
      "sku 8.93612E+12 not in text\n",
      "sku 8.93603E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.99889E+12 not in text\n",
      "sku 8.85182E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93525E+12 not in text\n",
      "sku 8.93459E+12 not in text\n",
      "sku 9.55609E+12 not in text\n",
      "sku 8.93604E+12 not in text\n",
      "sku 8.93487E+12 not in text\n",
      "sku 8.93501E+12 not in text\n",
      "sku 8.93458E+12 not in text\n",
      "sku 8.93468E+12 not in text\n",
      "sku 8.93514E+12 not in text\n",
      "sku 8.93468E+12 not in text\n",
      "sku 8.93476E+12 not in text\n",
      "sku 8.93457E+12 not in text\n",
      "sku 8.85182E+12 not in text\n",
      "sku 8.93456E+12 not in text\n",
      "sku 8.93467E+12 not in text\n",
      "sku 8.93507E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.936E+12 not in text\n",
      "sku 8.93468E+12 not in text\n",
      "sku 2.0035E+12 not in text\n",
      "sku 8.88834E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.9385E+12 not in text\n",
      "sku 8.93457E+12 not in text\n",
      "sku 8.85001E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93487E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93496E+12 not in text\n",
      "sku 8.9385E+12 not in text\n",
      "sku 8.93487E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93499E+12 not in text\n",
      "sku 8.93457E+12 not in text\n",
      "sku 2.00013E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93613E+12 not in text\n",
      "sku 8.93461E+12 not in text\n",
      "sku 8.93487E+12 not in text\n",
      "sku 8.93464E+12 not in text\n",
      "sku 8.93605E+12 not in text\n",
      "sku 8.93608E+12 not in text\n",
      "sku 8.93851E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93522E+12 not in text\n",
      "sku 8.80906E+12 not in text\n",
      "sku 8.93604E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93487E+12 not in text\n",
      "sku 8.93603E+12 not in text\n",
      "sku 8.93502E+12 not in text\n",
      "sku 8.93531E+12 not in text\n",
      "sku 8.93614E+12 not in text\n",
      "sku 8.996E+12 not in text\n",
      "sku 8.93502E+12 not in text\n",
      "sku 8.93607E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93852E+12 not in text\n",
      "sku 8.93468E+12 not in text\n",
      "sku 8.9385E+12 not in text\n",
      "sku 8.93502E+12 not in text\n",
      "sku 8.93467E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 5.09986E+12 not in text\n",
      "sku 8.93499E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93468E+12 not in text\n",
      "sku 8.9348E+12 not in text\n",
      "sku 8.9348E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93604E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.88834E+12 not in text\n",
      "sku 8.93505E+12 not in text\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = []\n",
    "for index, row in train.iterrows():\n",
    "    TRAIN_DATA.append((row['text'], {\"entities\": get_row_entities(row)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_entity_spans(data: list) -> list:\n",
    "\n",
    "    \"\"\"Removes leading and trailing white spaces from entity spans.\n",
    "\n",
    "    Args:\n",
    "    data (list): The data to be cleaned in spaCy JSON format.\n",
    "|\n",
    "    Returns:\n",
    "    list: The cleaned data.\n",
    "    \"\"\"\n",
    "    invalid_span_tokens = re.compile(r'\\s')\n",
    "\n",
    "    cleaned_data = []\n",
    "    for text, annotations in data:\n",
    "        entities = annotations['entities']\n",
    "        valid_entities = []\n",
    "        for start, end, label in entities:\n",
    "            valid_start = start\n",
    "            valid_end = end\n",
    "            # if there's preceding spaces, move the start position to nearest character\n",
    "            while valid_start < len(text) and invalid_span_tokens.match(\n",
    "                    text[valid_start]):\n",
    "                valid_start += 1\n",
    "            while valid_end > 1 and invalid_span_tokens.match(\n",
    "                    text[valid_end - 1]):\n",
    "                valid_end -= 1\n",
    "            valid_entities.append([valid_start, valid_end, label])\n",
    "        cleaned_data.append([text, {'entities': valid_entities}])\n",
    "    return cleaned_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['04902430779746  NX DOWNY doahoa ngotngao\\\\nVAT10%   1    38,053.21    38,053.21 \\\\nSo tien giam tuong ung:   49,946.79 \\\\nGia goc:   103,000.00 ',\n",
       "  {'entities': [[0, 14, 'sku'],\n",
       "    [45, 46, 'quantity'],\n",
       "    [56, 65, 'ppu'],\n",
       "    [69, 78, 'total_price'],\n",
       "    [107, 116, 'discounted_part'],\n",
       "    [130, 140, 'original_price'],\n",
       "    [16, 18, 'product_name'],\n",
       "    [19, 24, 'product_name'],\n",
       "    [25, 31, 'product_name'],\n",
       "    [32, 40, 'product_name']]}]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trim_entity_spans(TRAIN_DATA[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_spacy(TRAIN_DATA):\n",
    "    nlp = spacy.blank('en')  # create blank Language class\n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "\n",
    "\n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "         for ent in annotations.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(10):\n",
    "            print(\"Statring iteration \" + str(itn))\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            for text, annotations in TRAIN_DATA:\n",
    "                nlp.update(\n",
    "                [text],  # batch of texts\n",
    "                [annotations],  # batch of annotations\n",
    "                drop=0.2,  # dropout - make it harder to memorise data\n",
    "                sgd=optimizer,  # callable to update weights\n",
    "                losses=losses)\n",
    "            print(losses)\n",
    "    return nlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model=None, output_dir='.', n_iter=100):\n",
    "    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "\n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    # only train NER\n",
    "    with nlp.disable_pipes(*other_pipes), warnings.catch_warnings():\n",
    "        try:\n",
    "            # show warnings for misaligned entity spans once\n",
    "            warnings.filterwarnings(\"once\", category=UserWarning, module='spacy')\n",
    "\n",
    "            # reset and initialize the weights randomly â€“ but only if we're\n",
    "            # training a new model\n",
    "            if model is None:\n",
    "                nlp.begin_training()\n",
    "            for itn in range(n_iter):\n",
    "                random.shuffle(TRAIN_DATA)\n",
    "                losses = {}\n",
    "                # batch up the examples using spaCy's minibatch\n",
    "                batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "                for batch in batches:\n",
    "                    texts, annotations = zip(*batch)\n",
    "                    nlp.update(\n",
    "                        texts,  # batch of texts\n",
    "                        annotations,  # batch of annotations\n",
    "                        drop=0.5,  # dropout - make it harder to memorise data\n",
    "                        losses=losses,\n",
    "                    )\n",
    "                print(\"Losses\", losses)\n",
    "        except Exception as e:\n",
    "            print(texts, annotations)\n",
    "            raise e\n",
    "#     # test the trained model\n",
    "#     for text, _ in TRAIN_DATA:\n",
    "#         doc = nlp(text)\n",
    "#         print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "#         print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n",
    "\n",
    "    # save model to output directory\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir()\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-92367c8b828f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en_core_web_sm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mTRAIN_DATA\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Path or Path-like to model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "docs = []\n",
    "for text, annot in TRAIN_DATA:\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    tags = spacy.gold.biluo_tags_from_offsets(doc, annot['entities'])\n",
    "    \n",
    "    print(np.array(doc))\n",
    "    print(np.array(tags))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('04902430779746  NX DOWNY doahoa ngotngao\\\\nVAT10%   1    38,053.21    38,053.21 \\\\nSo tien giam tuong ung:   49,946.79 \\\\nGia goc:   103,000.00 ',\n",
       " {'entities': [(0, 14, 'sku'),\n",
       "   (45, 46, 'quantity'),\n",
       "   (56, 65, 'ppu'),\n",
       "   (69, 78, 'total_price'),\n",
       "   (107, 116, 'discounted_part'),\n",
       "   (130, 140, 'original_price'),\n",
       "   (16, 18, 'product_name'),\n",
       "   (19, 24, 'product_name'),\n",
       "   (25, 31, 'product_name'),\n",
       "   (32, 40, 'product_name')]})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(TRAIN_DATA[0][0][46:47])\n",
    "TRAIN_DATA[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = train_spacy(trim_entity_spans(TRAIN_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239\n"
     ]
    }
   ],
   "source": [
    "for i, row in enumerate(TRAIN_DATA):\n",
    "    if row[0].startswith('08936034200116'):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tuantv26\\Anaconda3\\envs\\FundaPython\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"08935005800015 N.khoang Lavie Sport pet\\nVAT10%   ...\" with entities \"[(0, 14, 'sku'), (44, 45, 'quantity'), (55, 63, 'p...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\tuantv26\\Anaconda3\\envs\\FundaPython\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"04902430779708 NX downy doahoa thom mat\\nVAT10%   ...\" with entities \"[(0, 14, 'sku'), (44, 45, 'quantity'), (55, 64, 'p...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\tuantv26\\Anaconda3\\envs\\FundaPython\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"04902430415637 NX DOWNY doahoa thom mat\\nVAT10%   ...\" with entities \"[(0, 14, 'sku'), (44, 45, 'quantity'), (55, 65, 'p...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\tuantv26\\Anaconda3\\envs\\FundaPython\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"08936065074361 ST OLIVdetox s.sau bve da\\nVAT10%  ...\" with entities \"[(0, 14, 'sku'), (45, 46, 'quantity'), (56, 65, 'p...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\tuantv26\\Anaconda3\\envs\\FundaPython\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"08934804038186  NESCAFE sua vi h.nhan 10x \\nVAT10%...\" with entities \"[(0, 14, 'sku'), (47, 48, 'quantity'), (58, 67, 'p...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\tuantv26\\Anaconda3\\envs\\FundaPython\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"08934673601825   S-Schua an VNM nha dam4hx\\nVAT10%...\" with entities \"[(0, 14, 'sku'), (53, 54, 'quantity'), (58, 67, 'p...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\tuantv26\\Anaconda3\\envs\\FundaPython\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"09556086010507  Sot Tomato ketchup LIFE 3\\nVAT10% ...\" with entities \"[(0, 14, 'sku'), (46, 47, 'quantity'), (57, 66, 'p...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\tuantv26\\Anaconda3\\envs\\FundaPython\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"08934585011125 Hoanh thanh tom thit TOP\\nVAT10%   ...\" with entities \"[(0, 14, 'sku'), (44, 45, 'quantity'), (55, 64, 'p...\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('00000002954821 S-ca basa nc bo dau tam u\\\\nVAT10%    70,000.00    34,440.00 \\\\n0.492 KG', '04902430415637 NX DOWNY doahoa thom mat\\\\nVAT10%   2    129,900.00    259,800.00 \\\\nGia goc:   159,000.00 ', '04902430647250 BG Tide huong Downy 3.8kg\\\\nVAT10%   1    127,000.00    127,000.00 \\\\nGia goc:   153,000.00 ', '00000002954486  Pate heo kg-BMQ\\\\nVAT10%    187,900.00    37,580.00 \\\\n0.200 KG') ({'entities': [(0, 14, 'sku'), (77, 85, 'quantity'), (52, 61, 'ppu'), (65, 74, 'total_price'), (15, 19, 'product_name'), (20, 24, 'product_name'), (25, 27, 'product_name'), (28, 30, 'product_name'), (31, 34, 'product_name'), (35, 38, 'product_name'), (33, 34, 'product_name')]}, {'entities': [(0, 14, 'sku'), (50, 51, 'quantity'), (55, 65, 'ppu'), (69, 79, 'total_price'), (93, 103, 'original_price'), (15, 17, 'product_name'), (18, 23, 'product_name'), (24, 30, 'product_name'), (31, 35, 'product_name'), (36, 39, 'product_name')]}, {'entities': [(0, 14, 'sku'), (45, 46, 'quantity'), (56, 66, 'ppu'), (70, 80, 'total_price'), (94, 104, 'original_price'), (15, 17, 'product_name'), (18, 22, 'product_name'), (23, 28, 'product_name'), (29, 34, 'product_name'), (35, 40, 'product_name')]}, {'entities': [(0, 14, 'sku'), (69, 77, 'quantity'), (43, 53, 'ppu'), (57, 66, 'total_price'), (16, 20, 'product_name'), (21, 24, 'product_name'), (25, 31, 'product_name')]})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E103] Trying to set conflicting doc.ents: '(31, 34, 'product_name')' and '(33, 34, 'product_name')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-7cf6ca1c5ca4>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(model, output_dir, n_iter)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;31m#     # test the trained model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m#     for text, _ in TRAIN_DATA:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-7cf6ca1c5ca4>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(model, output_dir, n_iter)\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                     \u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                     nlp.update(\n\u001b[0m\u001b[0;32m     45\u001b[0m                         \u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# batch of texts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                         \u001b[0mannotations\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# batch of annotations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\FundaPython\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, docs, golds, drop, sgd, losses, component_cfg)\u001b[0m\n\u001b[0;32m    508\u001b[0m             \u001b[0msgd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[1;31m# Allow dict of args to GoldParse, instead of GoldParse objects.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m         \u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgolds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format_docs_and_golds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\FundaPython\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m_format_docs_and_golds\u001b[1;34m(self, docs, golds)\u001b[0m\n\u001b[0;32m    480\u001b[0m                     \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE151\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munexp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munexpected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m                 \u001b[0mgold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGoldParse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mgold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m             \u001b[0mdoc_objs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m             \u001b[0mgold_objs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mgold.pyx\u001b[0m in \u001b[0;36mspacy.gold.GoldParse.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mgold.pyx\u001b[0m in \u001b[0;36mspacy.gold.biluo_tags_from_offsets\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E103] Trying to set conflicting doc.ents: '(31, 34, 'product_name')' and '(33, 34, 'product_name')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap."
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sku 4.90243E+12 not in text\n",
      "sku 8.93467E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93604E+12 not in text\n",
      "sku 8.9351E+12 not in text\n",
      "sku 8.93607E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93614E+12 not in text\n",
      "sku 8.9348E+12 not in text\n",
      "sku 8.93601E+12 not in text\n",
      "sku 8.93466E+12 not in text\n",
      "sku 8.93851E+12 not in text\n",
      "sku 8.93604E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93511E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93511E+12 not in text\n",
      "sku 8.9385E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93604E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93603E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93487E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93458E+12 not in text\n",
      "sku 8.93487E+12 not in text\n",
      "sku 8.93505E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93606E+12 not in text\n",
      "sku 8.9348E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93601E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93502E+12 not in text\n",
      "sku 8.93504E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.936E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93487E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93604E+12 not in text\n",
      "sku 8.93504E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93501E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93487E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93504E+12 not in text\n",
      "sku 8.93487E+12 not in text\n",
      "sku 8.93603E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93487E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 6.93144E+12 not in text\n",
      "sku 1.93335E+13 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 4.90243E+12 not in text\n",
      "sku 8.93511E+12 not in text\n",
      "sku 8.93501E+12 not in text\n",
      "sku 8.93471E+12 not in text\n"
     ]
    }
   ],
   "source": [
    "TEST_DATA = []\n",
    "for index, row in test.iterrows():\n",
    "    TEST_DATA.append((row['text'], {\"entities\": get_row_entities(row)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = test.iloc[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'04902430418287 NX DOWNY doahoa ngotngao\\\\nVAT10%   2    129,900.00    259,800.00 \\\\nGia goc:   159,000.00 '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from ../pretrained_models/NER\n",
      "Entities [('04902430418287', 'sku'), ('NX', 'product_name'), ('DOWNY', 'product_name'), ('doahoa', 'product_name'), ('2', 'quantity'), ('129,900.00', 'ppu'), ('259,800.00', 'total_price'), ('159,000.00', 'original_price')]\n",
      "Tokens [('04902430418287', 'sku', 3), ('NX', 'product_name', 3), ('DOWNY', 'product_name', 3), ('doahoa', 'product_name', 3), ('ngotngao\\\\nVAT10', '', 2), ('%', '', 2), ('  ', '', 2), ('2', 'quantity', 3), ('   ', '', 2), ('129,900.00', 'ppu', 3), ('   ', '', 2), ('259,800.00', 'total_price', 3), ('\\\\nGia', '', 2), ('goc', '', 2), (':', '', 2), ('  ', '', 2), ('159,000.00', 'original_price', 3)]\n"
     ]
    }
   ],
   "source": [
    "output_dir = '../pretrained_models/NER'\n",
    "\n",
    "print(\"Loading from\", output_dir)\n",
    "nlp2 = spacy.load(output_dir)\n",
    "# for text, _ in TEST_DATA:\n",
    "doc = nlp2(text)\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
